{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VwQfaCOcok"
      },
      "source": [
        "## Quantum Neural Network on $4 \\times 4$ downsampled Binary (3, 6) MNIST  \n",
        "Sebastian Molina  \n",
        "smolinad@unal.edu.co"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of the paper\n",
        "\n",
        "[Farhi et. al., Classification with Quantum Neural Networks\n",
        "on Near Term Processors](https://arxiv.org/pdf/1802.06002.pdf)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5hjuWaklL4kR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing and importing packages\n",
        "\n",
        "The variational circuit proposed in Farhi & Neven (2018), will be implemented in Tencent's `TensorCircuit`, using the provided Keras framework."
      ],
      "metadata": {
        "id": "QSFZ_EsRFvaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorcircuit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5IafHoCOqgN",
        "outputId": "b3135f54-fd0f-4452-96a6-4adb48926265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorcircuit\n",
            "  Downloading tensorcircuit-0.11.0-py3-none-any.whl (329 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/329.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/329.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m329.4/329.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (1.11.4)\n",
            "Collecting tensornetwork (from tensorcircuit)\n",
            "  Downloading tensornetwork-0.4.6-py3-none-any.whl (364 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.3/364.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (3.2.1)\n",
            "Requirement already satisfied: graphviz>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from tensornetwork->tensorcircuit) (0.20.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork->tensorcircuit) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork->tensorcircuit) (3.9.0)\n",
            "Installing collected packages: tensornetwork, tensorcircuit\n",
            "Successfully installed tensorcircuit-0.11.0 tensornetwork-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15DqVUX2Ocop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c11616-77f6-4146-fc83-3f5d803d6135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorcircuit.translation:Please first ``pip install -U qiskit`` to enable related functionality in translation module\n",
            "WARNING:tensorcircuit.translation:Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzQg29OoOcos"
      },
      "outputs": [],
      "source": [
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "img_height = 4\n",
        "n = img_height**2 #Number of qubits and pixels in the downsampled image\n",
        "nlayers = 3\n",
        "nsamples = 4000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-YCwe9eOcou"
      },
      "source": [
        "## MNIST data Preprocessing\n",
        "\n",
        "To train the model, one must preprocess the images, as even in simulations, it is quite difficult to process $784$ input qubits —as we are going to use basis encoding—. For starters, we are goint to work in binary classification, specifically, using numbers of classes $3$ and $6$.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\"\"\"\n",
        "Module for MNIST Digits Dataset preprocessing.\n",
        "https://www.tensorflow.org/quantum/tutorials/mnist\n",
        "\n",
        "Python 3.10.11\n",
        "\"\"\"\n",
        "\n",
        "def filter_by_classes(x, y, classes=[3,6]):\n",
        "    \"\"\"\n",
        "    Function that filters the MNIST Digits Dataset and returns samples on 'classes'.\n",
        "    Parameters:\n",
        "        x: Sample images.\n",
        "        y: Sample labels.\n",
        "        classes: List of classes to filter.\n",
        "    Returns:\n",
        "        x: x filtered by 'classes'.\n",
        "        y: x filtered by 'classes'.\n",
        "    \"\"\"\n",
        "    if not all(np.isin(classes, range(0, 10))):\n",
        "        return ValueError(\"Classes must be a list of digits (0-9).\")\n",
        "    x, y = x[np.isin(y, classes)], y[np.isin(y, classes)]\n",
        "    if len(classes)==2:\n",
        "        return x, y==classes[-1]\n",
        "    else:\n",
        "        return x, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0E8K0o3UAPs",
        "outputId": "35fa1f5f-93f5-478c-853c-755c07ed7709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Number of filtered training examples: 12049\n",
            "Number of filtered test examples: 1968\n",
            "Number of unique images: 10387\n",
            "Number of unique 3s:  5426\n",
            "Number of unique 6s:  4912\n",
            "Number of unique contradicting labels (both 3 and 6):  49\n",
            "\n",
            "Initial number of images:  12049\n",
            "Remaining non-contradicting unique images:  10338\n",
            "(10338, 16) (10338,) (1968, 16) (1968,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_contradicting(xs, ys):\n",
        "\n",
        "    mapping = collections.defaultdict(set)\n",
        "    orig_x = {}\n",
        "    # Determine the set of labels for each unique image:\n",
        "    for x,y in zip(xs,ys):\n",
        "       orig_x[tuple(x.flatten())] = x\n",
        "       mapping[tuple(x.flatten())].add(y)\n",
        "\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    for flatten_x in mapping:\n",
        "      x = orig_x[flatten_x]\n",
        "      labels = mapping[flatten_x]\n",
        "      if len(labels) == 1:\n",
        "          new_x.append(x)\n",
        "          new_y.append(next(iter(labels)))\n",
        "      else:\n",
        "          # Throw out images that match more than one label.\n",
        "          pass\n",
        "\n",
        "    num_uniq_3 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
        "    num_uniq_6 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
        "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
        "\n",
        "    print(\"Number of unique images:\", len(mapping.values()))\n",
        "    print(\"Number of unique 3s: \", num_uniq_3)\n",
        "    print(\"Number of unique 6s: \", num_uniq_6)\n",
        "    print(\"Number of unique contradicting labels (both 3 and 6): \", num_uniq_both)\n",
        "    print()\n",
        "    print(\"Initial number of images: \", len(xs))\n",
        "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
        "\n",
        "    return np.array(new_x), np.array(new_y)"
      ],
      "metadata": {
        "id": "SJe_QzUvF8qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We combine the preceeding methods into one function, where we will resample the MNIST digits images as $n \\times n$ images. In this case, we fixed the size as $4 \\times 4$ at the beginning."
      ],
      "metadata": {
        "id": "ap2ioLGCGODN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_mnist_digits(classes=[3,6]):\n",
        "    \"\"\"\"\n",
        "    Function that downloads the MNIST Digits dataset with TensorFlow and performs the following tasks:\n",
        "        1. Normalizes pixel values from (0, 255) to (0, 1).\n",
        "        2. By default, returns only 2 classes of digits for classification (this can be deactivated or modified by the 'classes' parameter).\n",
        "        3. Resizes samples to 4x4 images.\n",
        "        4. Removes samples that belong to multiple classes simultaneously.\n",
        "        5. Converts images to binary.\"\n",
        "    Parameters:\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "\n",
        "    # Download dataset\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "    x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
        "\n",
        "    # Filter to get only '3's and '6's\n",
        "    x_train, y_train = filter_by_classes(x_train, y_train, classes=classes)\n",
        "    x_test, y_test = filter_by_classes(x_test, y_test, classes=classes)\n",
        "\n",
        "    print(\"Number of filtered training examples:\", len(x_train))\n",
        "    print(\"Number of filtered test examples:\", len(x_test))\n",
        "\n",
        "    # Resize images to 4x4\n",
        "    x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
        "    x_test_small = tf.image.resize(x_test, (4,4)).numpy()\n",
        "\n",
        "    x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)\n",
        "\n",
        "    THRESHOLD = 0.5\n",
        "\n",
        "    # Converts non contradicting samples to binary via threshold and converting bool to float.\n",
        "    x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
        "    x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)\n",
        "\n",
        "    return x_train_bin.reshape(-1, 16), y_train_nocon, x_test_bin.reshape(-1, 16), y_test"
      ],
      "metadata": {
        "id": "D0FmwPliF-ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_test, Y_test = preprocess_mnist_digits()\n",
        "X_train *= np.pi\n",
        "X_test *= np.pi\n",
        "Y_train = np.where(Y_train==False, -1, 1)\n",
        "Y_test = np.where(Y_test==False, -1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbsmrP3oGFmK",
        "outputId": "8ac41cea-c877-47f2-c8c4-c1d6ea4d9b98"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of filtered training examples: 12049\n",
            "Number of filtered test examples: 1968\n",
            "Number of unique images: 10387\n",
            "Number of unique 3s:  5426\n",
            "Number of unique 6s:  4912\n",
            "Number of unique contradicting labels (both 3 and 6):  49\n",
            "\n",
            "Initial number of images:  12049\n",
            "Remaining non-contradicting unique images:  10338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuMraZaNOcoy"
      },
      "source": [
        "### Quantum variational classifier\n",
        "Following the instructions of Farhi & Neven (2018), we implemented the variational classifier as follows:\n",
        "- We receive $n^2 = 16$ entries as inputs, corresponding to each pixel in the downsampled image.\n",
        "- We append one readout qubit, where rotations are applied according to the data entries.\n",
        "- Rotations are applied in a 3-fold sequence of intertwined $R_{ZX}$ and $R_{XX}$ gates, found after experimental trial and error.\n",
        "- Finally, the readout qubit is measured."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lai3UBDtOco0"
      },
      "outputs": [],
      "source": [
        "def variational_classifier(x, weights, nlayers):\n",
        "\n",
        "    c = tc.Circuit(n+1)\n",
        "\n",
        "    c.x(0)\n",
        "\n",
        "    for i in range(1, n+1):\n",
        "      c.rx(i, theta=x[i-1])\n",
        "\n",
        "    for i in range(nlayers):\n",
        "        for j in range(1, n+1):\n",
        "          if i%2 == 0:\n",
        "            c.exp1(j, 0, unitary=tc.gates._zx_matrix, theta=weights[i, j-1])\n",
        "          else:\n",
        "            c.exp1(j, 0, unitary=tc.gates._xx_matrix, theta=weights[i, j-1])\n",
        "\n",
        "    return tc.backend.real(c.expectation((tc.gates.y(), [0])))\n",
        "\n",
        "\n",
        "layer = keras.QuantumLayer(partial(variational_classifier, nlayers=nlayers), [(2 * nlayers, n)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Keras interface is used to implement the variational classifier. A parameter tensor is initialized for each layer, with size $3 \\cdot 2 \\times n^2$. In this case, we won't use the results in the paper to calculate the gradient, as calculations where shown to be dependant on $L+2 \\cdot 16 = 8 \\times 16$ unitary gates. We will rely on a classical optimizer for the minimization of the loss function."
      ],
      "metadata": {
        "id": "jzHV12FLGaiN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiB9GIesOco2",
        "outputId": "532b930c-279a-4099-878c-65e18e17313c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "647/647 [==============================] - 313s 473ms/step - loss: 0.3835 - binary_accuracy: 0.3666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7877b2846530>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Keras interface with Keras training paradigm\n",
        "\n",
        "model = tf.keras.Sequential([layer])\n",
        "\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.Hinge(),\n",
        "    optimizer=tf.keras.optimizers.legacy.Adam(0.01),\n",
        "    metrics=[\"binary_accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(X_train, Y_train, batch_size=16, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result\n",
        "\n",
        "Here we obtain the result of the variational circuit classification. We observe it is close to the accuracy showed in the paper."
      ],
      "metadata": {
        "id": "pNs8Gm4TGdmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "accuracy_score(Y_test > 0, Y_pred > 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYbBvg3KUZPb",
        "outputId": "02b8fa4a-2973-46e0-9d2e-69ccd05c8172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 37s 256ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9034552845528455"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "1. https://www.tensorflow.org/quantum/tutorials/mnist\n",
        "2. https://tensorcircuit.readthedocs.io/en/latest/tutorials/mnist_qml.html\n",
        "3. https://arxiv.org/abs/1802.06002"
      ],
      "metadata": {
        "id": "d79xmmaAGsMi"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}