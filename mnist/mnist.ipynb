{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Neural Network on $3 \\times 3$ downsampled MNIST Digits  \n",
    "Sebastian Molina  \n",
    "smolinad@unal.edu.co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorcircuit as tc\n",
    "from tensorcircuit import keras\n",
    "\n",
    "from mnist_preprocessing import preprocess_mnist_digits as mnist\n",
    "\n",
    "from classical_neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.set_backend(\"tensorflow\")\n",
    "tc.set_dtype(\"complex128\")\n",
    "\n",
    "img_height = 3\n",
    "n = img_height**2 #Number of qubits and pixels in the downsampled image\n",
    "nlayers = 3 \n",
    "nsamples = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train, x_test, y_test = mnist(img_height=n)\n",
    "# x_train = np.squeeze(x_train)[:nsamples]\n",
    "# x_train = tf.reshape(tf.constant(x_train, dtype=tf.float64), [-1, n])\n",
    "# y_train = tf.constant(y_train[:nsamples], dtype=tf.float64)\n",
    "\n",
    "# x_test = tf.reshape(tf.constant(x_test, dtype=tf.float64), [-1, n])\n",
    "# y_test = tf.constant(y_test, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train[..., np.newaxis] / 255.0\n",
    "x_test = x_test[..., np.newaxis] / 255.0\n",
    "\n",
    "\n",
    "def filter_pair(x, y, a, b):\n",
    "    keep = (y == a) | (y == b)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == a\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = filter_pair(x_train, y_train, 3, 6)\n",
    "x_test, y_test = filter_pair(x_test, y_test, 3, 6)\n",
    "\n",
    "x_train_small = tf.image.resize(x_train, (img_height, img_height)).numpy()\n",
    "x_train_bin = np.array(x_train_small > 0.5, dtype=np.float32)\n",
    "x_train_bin = np.squeeze(x_train_bin)[:nsamples]\n",
    "x_train = tf.reshape(tf.constant(x_train_bin, dtype=tf.float64), [-1, n])\n",
    "y_train = tf.constant(y_train[:nsamples], dtype=tf.float64)\n",
    "\n",
    "x_test_small = tf.image.resize(x_test, (img_height, img_height)).numpy()\n",
    "x_test_bin = np.array(x_test_small > 0.5, dtype=np.float32)\n",
    "x_test = tf.reshape(tf.constant(x_test_bin, dtype=tf.float64), [-1, n])\n",
    "y_test = tf.constant(y_test, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum variational classifier (Farhi & Neven) \n",
    "No vmap or vvag optimization. Using vmap runs way faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(x, weights, nlayers):\n",
    "\n",
    "    c = tc.Circuit(n+1)\n",
    "\n",
    "    for i in range(n):\n",
    "        c.rx(i, theta=x[i])\n",
    "            \n",
    "    c.X(n)\n",
    "    c.H(n)\n",
    "\n",
    "    for i in range(nlayers):\n",
    "        for j in range(n):\n",
    "            c.exp1(j, n, unitary=tc.gates._zx_matrix, theta=weights[2*i, j])\n",
    "            c.exp1(j, n, unitary=tc.gates._xx_matrix, theta=weights[2*i+1, j])\n",
    "                \n",
    "    c.H(n)\n",
    "\n",
    "    ## Changing to original measurement (returning c.Z(n)) ends in bad accuracy.\n",
    "    ypred = c.expectation([tc.gates.z(), (4, )]) #Why (4,)\n",
    "    ypred = (tc.backend.real(ypred) + 1) / 2.0 #Why divide in two. Related: https://tensorcircuit.readthedocs.io/en/latest/tutorials/mnist_qml.html?highlight=MNIST\n",
    "    return ypred\n",
    "\n",
    "\n",
    "layer = keras.QuantumLayer(partial(variational_classifier, nlayers=nlayers), [(2 * nlayers, n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 24s 46ms/step - loss: 0.6944 - binary_accuracy: 0.6398\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.6164 - binary_accuracy: 0.6955\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.6175 - binary_accuracy: 0.6955\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 0.6173 - binary_accuracy: 0.6955\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 7s 53ms/step - loss: 0.6157 - binary_accuracy: 0.6955\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.6190 - binary_accuracy: 0.6955\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.6170 - binary_accuracy: 0.6955\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.6165 - binary_accuracy: 0.6955\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.6198 - binary_accuracy: 0.6955\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.6176 - binary_accuracy: 0.6955\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.6162 - binary_accuracy: 0.6955\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.6174 - binary_accuracy: 0.6955\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.6163 - binary_accuracy: 0.6955\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 6s 51ms/step - loss: 0.6154 - binary_accuracy: 0.6955\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 7s 52ms/step - loss: 0.6160 - binary_accuracy: 0.6955\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 7s 53ms/step - loss: 0.6168 - binary_accuracy: 0.6955\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 7s 53ms/step - loss: 0.6167 - binary_accuracy: 0.6955\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.6170 - binary_accuracy: 0.6955\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 6s 49ms/step - loss: 0.6163 - binary_accuracy: 0.6955\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 6s 50ms/step - loss: 0.6180 - binary_accuracy: 0.6955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29f3bf940>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keras interface with Keras training paradigm\n",
    "\n",
    "model = tf.keras.Sequential([layer])\n",
    "\n",
    "def hinge_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true) > 0.0\n",
    "    y_pred = tf.squeeze(y_pred) > 0.0\n",
    "    result = tf.cast(y_true == y_pred, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(result)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\", #Because labels are in [0, 1] range. Can be changed to hinge loss if labels are transformed to [-1, 1]. Related: https://www.tensorflow.org/quantum/tutorials/mnist#2_quantum_neural_network\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(0.01),\n",
    "    metrics=[\"binary_accuracy\"],\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=20)\n",
    "#[:int(nsamples/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 11s 23ms/step - loss: 0.6188 - binary_accuracy: 0.6956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6188288331031799, 0.6955645084381104]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original example (TensorCircuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qml_y(x, weights, nlayers):\n",
    "    weights = tc.backend.cast(weights, \"complex128\")\n",
    "    x = tc.backend.cast(x, \"complex128\")\n",
    "    c = tc.Circuit(n)\n",
    "    for i in range(n):\n",
    "        c.rx(i, theta=x[i])\n",
    "    for j in range(nlayers):\n",
    "        for i in range(n - 1):\n",
    "            c.cnot(i, i + 1)\n",
    "        for i in range(n):\n",
    "            c.rx(i, theta=weights[2 * j, i])\n",
    "            c.ry(i, theta=weights[2 * j + 1, i])\n",
    "    ypred = c.expectation([tc.gates.z(), (4,)])\n",
    "    ypred = tc.backend.real(ypred)\n",
    "    ypred = (tc.backend.real(ypred) + 1) / 2.0\n",
    "    return ypred\n",
    "\n",
    "ql = keras.QuantumLayer(partial(qml_y, nlayers=nlayers), [(2 * nlayers, n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 12s 5ms/step - loss: 0.6785 - binary_accuracy: 0.5990\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6529 - binary_accuracy: 0.6925\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6464 - binary_accuracy: 0.6908\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6451 - binary_accuracy: 0.7028\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 1s 8ms/step - loss: 0.6440 - binary_accuracy: 0.7028\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6443 - binary_accuracy: 0.7057\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6436 - binary_accuracy: 0.7067\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6430 - binary_accuracy: 0.7103\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6431 - binary_accuracy: 0.7107\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6431 - binary_accuracy: 0.6963\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6416 - binary_accuracy: 0.7163\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6412 - binary_accuracy: 0.7140\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6404 - binary_accuracy: 0.7040\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6397 - binary_accuracy: 0.7160\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6404 - binary_accuracy: 0.7130\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.6400 - binary_accuracy: 0.7153\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 1s 7ms/step - loss: 0.6384 - binary_accuracy: 0.7038\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6401 - binary_accuracy: 0.7025\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6391 - binary_accuracy: 0.7048\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 1s 6ms/step - loss: 0.6410 - binary_accuracy: 0.7103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2e736a320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras interface with keras training paradigm\n",
    "\n",
    "model1 = tf.keras.Sequential([ql])\n",
    "\n",
    "model1.compile(\n",
    "    loss=\"binary_crossentropy\", #Because labels are in [0, 1] range. Can be changed to hinge loss if labels are transformed to [-1, 1]. Related: https://www.tensorflow.org/quantum/tutorials/mnist#2_quantum_neural_network\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(0.01),\n",
    "    metrics=[\"binary_accuracy\"],\n",
    ")\n",
    "\n",
    "model1.fit(x_train, y_train, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 8s 2ms/step - loss: 0.6373 - binary_accuracy: 0.7208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6373297572135925, 0.7207661271095276]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classical Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = NeuralNetwork(input_shape=(n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 0s 580us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 0s 521us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 0s 520us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 0s 519us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 0s 511us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 0s 524us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 0s 518us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 0s 530us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 0s 661us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 0s 553us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 0s 559us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 0s 550us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 0s 548us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 0s 547us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 0s 546us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 0s 551us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 0s 529us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 0s 532us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 0s 540us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 0s 532us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 0s 538us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 0s 538us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 0s 540us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 0s 529us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 0s 534us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 0s 530us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 0s 538us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 0s 544us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 0s 542us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 0s 530us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 0s 531us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 0s 550us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 0s 831us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 0s 595us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 0s 525us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 0s 533us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 0s 531us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 0s 535us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 0s 538us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 0s 542us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 0s 533us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 0s 547us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 0s 539us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 0s 543us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 0s 534us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 0s 532us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 0s 531us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 0s 535us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 0s 530us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 0s 529us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 0s 528us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 0s 533us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 0s 531us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 0s 528us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 0s 534us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 0s 534us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 0s 541us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 0s 536us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 0s 531us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 0s 532us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 0s 536us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 0s 531us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 0s 531us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 0s 539us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 0s 574us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 0s 532us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 0s 536us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 0s 534us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 0s 574us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 0s 556us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 0s 555us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 0s 541us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 0s 551us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 0s 537us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 0s 536us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 0s 532us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 0s 547us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 0s 567us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 0s 534us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 0s 533us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 0s 528us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 0s 537us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 0s 545us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 0s 533us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 0s 885us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 0s 561us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 0s 572us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 0s 625us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 0s 579us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 0s 731us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 0s 853us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 0s 645us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 0s 610us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 0s 613us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 0s 592us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 0s 547us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 0s 554us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 0s 550us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 0s 547us/step - loss: 7.9207 - binary_accuracy: 0.4865\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 0s 552us/step - loss: 7.9207 - binary_accuracy: 0.4865\n"
     ]
    }
   ],
   "source": [
    "neural_network.train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somehow not working with $3 \\times 3$ images, but it works with $4 \\times 4.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 544us/step - loss: 7.9163 - binary_accuracy: 0.4868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.916258811950684, 0.48678863048553467]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
